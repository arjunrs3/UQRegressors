{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09d91c4c",
   "metadata": {},
   "source": [
    "# Regressor Validation Demo\n",
    "\n",
    "This notebook demonstrates how to train, tune, validate, and compare uncertainty-aware regression models using the UQRegressors library. It is designed for users new to the code base and provides detailed documentation for each step.\n",
    "\n",
    "**Covered methods:**\n",
    "- MC Dropout\n",
    "- Deep Ensemble\n",
    "- Split Conformal Quantile Regression (CQR)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Import Required Libraries and Set Up Environment\n",
    "\n",
    "In this section, we import all necessary Python libraries and modules, and set up the computational environment (CPU/GPU, random seeds). Each import and setup step is explained for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bb6fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core Python libraries for data handling and computation\n",
    "import numpy as np  # Numerical operations\n",
    "import pandas as pd  # Data manipulation\n",
    "import torch  # PyTorch for deep learning\n",
    "import matplotlib.pyplot as plt  # Plotting\n",
    "\n",
    "# Import UQRegressors components for uncertainty-aware regression\n",
    "from uqregressors.bayesian.dropout import MCDropoutRegressor\n",
    "from uqregressors.bayesian.deep_ens import DeepEnsembleRegressor\n",
    "from uqregressors.conformal.cqr import ConformalQuantileRegressor\n",
    "from uqregressors.metrics.metrics import compute_all_metrics\n",
    "from uqregressors.utils.file_manager import FileManager\n",
    "from uqregressors.utils.torch_sklearn_utils import train_test_split\n",
    "\n",
    "# Set up device (GPU if available, else CPU)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaa81cb",
   "metadata": {},
   "source": [
    "## 2. Utility Functions for Regressor Validation\n",
    "\n",
    "This section defines utility functions to streamline the process of training, tuning, and evaluating regressors. Each function is documented to help new users understand its purpose and usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb5186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for training, tuning, and evaluating regressors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import optuna\n",
    "\n",
    "# Set Optuna logging to warning for cleaner output\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "def test_regressor(model, X, y, dataset_name, test_size, seed=None, \n",
    "                   tuning_epochs=None, param_space=None, scoring_fn=None, greater=None,\n",
    "                   initial_params=None, n_trials=None, n_splits=1):\n",
    "    \"\"\"\n",
    "    Train and evaluate a regressor on a dataset, with optional hyperparameter tuning.\n",
    "    Returns a dictionary of evaluation metrics.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    # Split data into train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "\n",
    "    # Hyperparameter tuning (if specified)\n",
    "    if tuning_epochs is not None and param_space is not None:\n",
    "        epochs_copy = model.epochs\n",
    "        model.epochs = deepcopy(tuning_epochs)\n",
    "        from uqregressors.tuning.tuning import tune_hyperparams\n",
    "        opt_model, opt_score, study = tune_hyperparams(\n",
    "            regressor=model,\n",
    "            param_space=param_space,\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            score_fn=scoring_fn,\n",
    "            greater_is_better=greater,\n",
    "            initial_params=initial_params,\n",
    "            n_trials=n_trials,\n",
    "            n_splits=n_splits,\n",
    "            verbose=False\n",
    "        )\n",
    "        model = opt_model\n",
    "        model.epochs = epochs_copy\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    mean, lower, upper = model.predict(X_test)\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    metrics = compute_all_metrics(mean, lower, upper, y_test, model.alpha)\n",
    "    metrics[\"mse\"] = mean_squared_error(y_test, mean)\n",
    "    return metrics\n",
    "\n",
    "def run_regressor_test(model, datasets, seed, filename, test_size,\n",
    "                       BASE_SAVE_DIR=Path.home()/\".uqregressors\",\n",
    "                       tuning_epochs=None, param_space=None, scoring_fn=None, greater=None,\n",
    "                       initial_params=None, n_trials=None, n_splits=1):\n",
    "    \"\"\"\n",
    "    Run a regressor on multiple datasets, save models and metrics, and return save paths.\n",
    "    \"\"\"\n",
    "    saved_results = []\n",
    "    for name, (X, y) in datasets.items():\n",
    "        print(f\"\\nRunning on dataset: {name}\")\n",
    "        metrics = test_regressor(model, X, y, name, seed=seed, test_size=test_size,\n",
    "                                 tuning_epochs=tuning_epochs, param_space=param_space,\n",
    "                                 scoring_fn=scoring_fn, greater=greater, initial_params=initial_params,\n",
    "                                 n_trials=n_trials, n_splits=n_splits)\n",
    "        print(metrics)\n",
    "        fm = FileManager(BASE_SAVE_DIR)\n",
    "        save_path = fm.save_model(model, name=name + \"_\" + filename, metrics=metrics)\n",
    "        saved_results.append((model.__class__, name, save_path))\n",
    "    return saved_results\n",
    "\n",
    "def print_results(paths):\n",
    "    \"\"\"\n",
    "    Load and print metrics for each saved model.\n",
    "    \"\"\"\n",
    "    fm = FileManager()\n",
    "    for cls, dataset_name, path in paths:\n",
    "        results = fm.load_model(cls, path=path, load_logs=False)\n",
    "        print(f\"Results for {dataset_name}\")\n",
    "        print(results[\"metrics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194e3152",
   "metadata": {},
   "source": [
    "## 3. Dataset Preparation and Loading\n",
    "\n",
    "This section shows how to download, load, and preprocess datasets for regression experiments. We use a synthetic dataset for demonstration and show how to prepare real datasets (e.g., UCI protein) as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac760dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Generate a synthetic regression dataset\n",
    "# This is useful for quick testing and demonstration\n",
    "\n",
    "def generate_synthetic_data(n_samples=200, n_features=5):\n",
    "    \"\"\"Generate a simple synthetic regression dataset.\"\"\"\n",
    "    X = np.random.randn(n_samples, n_features)\n",
    "    y = np.sin(X[:, 0]) + X[:, 1] ** 2 + np.random.normal(0, 0.1, size=n_samples)\n",
    "    return X, y\n",
    "\n",
    "# Prepare datasets dictionary for use in validation functions\n",
    "datasets = {\n",
    "    \"synthetic\": generate_synthetic_data()\n",
    "}\n",
    "\n",
    "# Example: How to load a real dataset (UCI protein)\n",
    "# Uncomment and run the following code to download and prepare the UCI protein dataset\n",
    "# import pandas as pd\n",
    "# from io import StringIO\n",
    "# import requests\n",
    "# uci_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00265/CASP.csv\"\n",
    "# response = requests.get(uci_url)\n",
    "# df = pd.read_csv(StringIO(response.text))\n",
    "# X_protein = df.drop(columns=[\"RMSD\"]).values\n",
    "# y_protein = df[\"RMSD\"].values\n",
    "# datasets[\"protein\"] = (X_protein, y_protein)\n",
    "\n",
    "print(\"Datasets prepared:\", list(datasets.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d40c091",
   "metadata": {},
   "source": [
    "## 4. MC Dropout Regressor: Training, Tuning, and Validation\n",
    "\n",
    "This section demonstrates how to configure, tune, train, and validate an MC Dropout regressor. Hyperparameter tuning is performed using Optuna, and results are evaluated using standard metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78404d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and validate an MC Dropout regressor\n",
    "from uqregressors.tuning.tuning import log_likelihood\n",
    "\n",
    "# Define the MC Dropout regressor with basic settings\n",
    "mc_dropout = MCDropoutRegressor(\n",
    "    hidden_sizes=[50],\n",
    "    dropout=0.05,\n",
    "    use_paper_weight_decay=True,\n",
    "    prior_length_scale=1e-2,\n",
    "    alpha=0.05,\n",
    "    n_samples=100,\n",
    "    epochs=40,  # Fewer epochs for demonstration\n",
    "    batch_size=32,\n",
    "    learning_rate=1e-3,\n",
    "    device=device,\n",
    "    use_wandb=False\n",
    ")\n",
    "\n",
    "# Define hyperparameter search space for tau (aleatoric uncertainty)\n",
    "param_space = {\n",
    "    \"tau\": lambda trial: trial.suggest_float(\"tau\", 1e-2, 1e2, log=True)\n",
    "}\n",
    "\n",
    "# Run validation on all datasets (synthetic by default)\n",
    "mc_save_paths = run_regressor_test(\n",
    "    mc_dropout, datasets, seed=42, filename=\"dropout_demo\", test_size=0.2,\n",
    "    tuning_epochs=20, param_space=param_space, scoring_fn=log_likelihood, greater=True, n_trials=10\n",
    ")\n",
    "\n",
    "# Print results for each dataset\n",
    "print_results(mc_save_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266757d0",
   "metadata": {},
   "source": [
    "## 5. Deep Ensemble Regressor: Training and Validation\n",
    "\n",
    "This section demonstrates how to set up, train, and validate a Deep Ensemble regressor. Any dataset-specific settings (such as learning rate) are explained in comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0fa483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and validate a Deep Ensemble regressor\n",
    "# Deep Ensembles are robust and often perform well on a variety of datasets\n",
    "\n",
    "deep_ens = DeepEnsembleRegressor(\n",
    "    n_estimators=3,  # Fewer estimators for demonstration\n",
    "    hidden_sizes=[50],\n",
    "    n_jobs=1,  # Set to >1 for parallel training if supported\n",
    "    alpha=0.05,\n",
    "    batch_size=64,\n",
    "    learning_rate=1e-2,  # Adjust as needed for your dataset\n",
    "    epochs=20,\n",
    "    device=device,\n",
    "    scale_data=True,\n",
    "    use_wandb=False\n",
    ")\n",
    "\n",
    "deep_ens_save_paths = run_regressor_test(\n",
    "    deep_ens, datasets, seed=42, filename=\"deep_ens_demo\", test_size=0.2\n",
    ")\n",
    "\n",
    "print_results(deep_ens_save_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4021c6f",
   "metadata": {},
   "source": [
    "## 6. Split Conformal Quantile Regression: Training, Tuning, and Validation\n",
    "\n",
    "This section demonstrates how to configure, tune, and validate a Split Conformal Quantile Regressor (CQR). The hyperparameter search space and evaluation metrics are explained in comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e4c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and validate a Split Conformal Quantile Regressor (CQR)\n",
    "from uqregressors.tuning.tuning import interval_width\n",
    "\n",
    "cqr = ConformalQuantileRegressor(\n",
    "    hidden_sizes=[32, 32],\n",
    "    cal_size=0.5,  # Fraction of training data for calibration\n",
    "    alpha=0.1,\n",
    "    dropout=0.1,\n",
    "    epochs=40,\n",
    "    batch_size=32,\n",
    "    learning_rate=1e-3,\n",
    "    optimizer_kwargs={\"weight_decay\": 1e-6},\n",
    "    device=device,\n",
    "    scale_data=True,\n",
    "    use_wandb=False\n",
    ")\n",
    "\n",
    "# Hyperparameter search space for quantile levels\n",
    "tau_param_space = {\n",
    "    \"tau_lo\": lambda trial: trial.suggest_float(\"tau_lo\", 0.03, 0.1),\n",
    "    \"tau_hi\": lambda trial: trial.suggest_float(\"tau_hi\", 0.9, 0.97)\n",
    "}\n",
    "\n",
    "cqr_save_paths = run_regressor_test(\n",
    "    cqr, datasets, seed=42, filename=\"cqr_demo\", test_size=0.2,\n",
    "    tuning_epochs=20, param_space=tau_param_space, scoring_fn=interval_width, greater=False, n_trials=5, n_splits=2\n",
    ")\n",
    "\n",
    "print_results(cqr_save_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebaf4ed",
   "metadata": {},
   "source": [
    "## 7. Visualization of Validation Results\n",
    "\n",
    "This section provides functions and code to visualize and compare experimental results with published benchmarks. Plots help interpret the performance of each regressor and understand the effect of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cb0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Compare predicted vs. true values and interval widths\n",
    "# This function can be adapted to visualize results for any regressor\n",
    "\n",
    "def plot_predictions(X_test, y_test, mean, lower, upper, title=\"Prediction Intervals\"): \n",
    "    \"\"\"Plot predicted mean and uncertainty intervals against true values.\"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(y_test, label=\"True values\", marker=\"o\", linestyle=\"None\", alpha=0.5)\n",
    "    plt.plot(mean, label=\"Predicted mean\", color=\"red\")\n",
    "    plt.fill_between(range(len(mean)), lower, upper, color=\"orange\", alpha=0.3, label=\"Prediction interval\")\n",
    "    plt.xlabel(\"Test sample index\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage (for the last trained model on the synthetic dataset):\n",
    "# Load the last saved model and data\n",
    "fm = FileManager()\n",
    "last_path = mc_save_paths[-1][2]  # Use MC Dropout as example\n",
    "load_dict = fm.load_model(MCDropoutRegressor, last_path, load_logs=False)\n",
    "mean, lower, upper = load_dict[\"model\"].predict(load_dict[\"X_test\"])\n",
    "plot_predictions(load_dict[\"X_test\"], load_dict[\"y_test\"], mean, lower, upper, title=\"MC Dropout: Synthetic Data\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
